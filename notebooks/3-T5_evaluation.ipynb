{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5757f0c-344a-4fc9-986c-0054ae061259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782e623d-21e7-486e-a99f-f7196259941f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# fine-tuned model for text detoxification\n",
    "# finetuned_model_chk = \"../models/T5_training_checkpoints/final_checkpoint/\"\n",
    "finetuned_model_chk = \"../models/T5_checkpointsV2/final_checkpointV2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_chk)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_chk).to(device)\n",
    "\n",
    "# tokenizer and model weights for calculating toxisity score of the text\n",
    "toxic_tokenizer = RobertaTokenizer.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')\n",
    "toxic_model = RobertaForSequenceClassification.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8505c6e-d767-4851-a1a2-a0fa5c2fff5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_toxisity_score(model_output):\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    scores = sigmoid(model_output.squeeze()).cpu().detach().numpy()\n",
    "    result = {'neutral' : scores[0], 'toxic' : scores[1]}\n",
    "    return result\n",
    "\n",
    "def get_classification(text, classification_tokenizer=toxic_tokenizer, classification_model=toxic_model):\n",
    "    tokenized_text = classification_tokenizer.encode(text, return_tensors='pt')\n",
    "    predictions = classification_model(tokenized_text)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# output = get_classification('Fuck you', tokenizer_toxisity_score, model_toxisity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5dca26-94c5-4745-af3b-7a00a2af4224",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6b9ce10439477aaf73c5fe1a1d0ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217bdf3c41344a15a30948bfa1ca0322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f134e07324d59b1f2b8cc8f4e8042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f81a0e9361b46dfa64f3280480cdb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = 's-nlp/paradetox'\n",
    "dataset = datasets.load_dataset(dataset_path)['train']\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064cad35-6d55-4b35-9ca9-07fa83b17a80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979ebe1d45394e38bf10c9bf2ad04f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "detoxified_ressults = []\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    toxic_batch, neutral_batch = batch['en_toxic_comment'], batch['en_neutral_comment']\n",
    "    tokenized_toxic_batch = tokenizer(toxic_batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "    responce = model.generate(**tokenized_toxic_batch, max_new_tokens=512)\n",
    "    results = tokenizer.batch_decode(responce, skip_special_tokens=True)\n",
    "    detoxified_ressults.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6232945a-77be-423e-9507-6ffb55970ac1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19744,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detoxified_ressults = np.array(detoxified_ressults).flatten()\n",
    "detoxified_ressults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd5140e-2bd0-4bd3-866d-f3f14bd32e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('T5_paraphrased', detoxified_ressults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2297b17-f207-4df0-abe7-82af1d298391",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e00f749-3384-4a10-99b7-bb6b5bd62dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3bc2920228416581268a749459426f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_toxicity_val = []\n",
    "detoxified_toxicity_val = []\n",
    "paraphrased_toxicity_val = []\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    toxic_comments_batch, detoxified_comments_batch, paraphrased_comments_batch = (\n",
    "        batch[\"en_toxic_comment\"],\n",
    "        batch[\"en_neutral_comment\"],\n",
    "        batch[\"T5_paraphrased\"],\n",
    "    )\n",
    "    t = toxic_tokenizer(toxic_comments_batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "    res = toxic_model(**t)\n",
    "    for elem in res.logits:\n",
    "        init_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n",
    "\n",
    "    t = toxic_tokenizer(detoxified_comments_batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "    res = toxic_model(**t)\n",
    "    for elem in res.logits:\n",
    "        detoxified_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n",
    "\n",
    "    t = toxic_tokenizer(paraphrased_comments_batch, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "    res = toxic_model(**t)\n",
    "    for elem in res.logits:\n",
    "        paraphrased_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf93339-edfb-42dd-9edf-68557faf46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('initial_toxicity', init_toxicity_val)\n",
    "dataset = dataset.add_column('ideal_toxicity', detoxified_toxicity_val)\n",
    "dataset = dataset.add_column('resulting_toxicity', paraphrased_toxicity_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "774f9efa-d4a5-4231-b3f3-c278fa8bb76b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "simmilarity_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "cosine_simmilarity = nn.CosineSimilarity(dim=0)\n",
    "\n",
    "def get_sim(text1, text2):\n",
    "    embeddings = simmilarity_model.encode([text1, text2], convert_to_tensor=True)\n",
    "    return cosine_simmilarity(embeddings[0], embeddings[1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1222c65-3224-40ee-beb8-152d65b33963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c3921c58e04d63bc4ca6d29bd928a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference2masked_sim = []\n",
    "reference2translation_sim = []\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    toxic = example['en_toxic_comment']\n",
    "    nontoxic = example['en_neutral_comment']\n",
    "    masked = example['T5_paraphrased']\n",
    "    reference2masked_sim.append(get_sim(toxic, masked))\n",
    "    reference2translation_sim.append(get_sim(toxic, nontoxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e8b049-b5e8-4b8d-a533-d0b64acbe60f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('reference2masked_sim', reference2masked_sim)\n",
    "dataset = dataset.add_column('reference2translation_sim', reference2translation_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290ee515-b492-40c6-a35f-927bc011e83a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fluency_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/roberta-large-cola-krishna2020\")\n",
    "fluency_model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/roberta-large-cola-krishna2020\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78534168-be6f-4ea9-91f3-600a86a18254",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fluency_score(logits):\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    scores = sigmoid(logits.squeeze()).cpu().detach().numpy()\n",
    "    result = {\"Fluent\": scores[0], \"Non-Fluent\": scores[1]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dbc7a1f-e096-4594-8bb7-7cb96f6c49f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc6143c1-39cd-42f3-be60-b6dc9b136b6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867469b3aee14e3e8b8093d04b68ba75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fluency_scores = []\n",
    "for batch in tqdm(dataloader):\n",
    "    text = batch['T5_paraphrased']\n",
    "    tokens = fluency_tokenizer(text, return_tensors='pt', truncation=True, padding='max_length').to(device)\n",
    "    result = fluency_model(**tokens).logits\n",
    "    for elem in result:\n",
    "        elem_res = get_fluency_score(elem)['Fluent']\n",
    "        fluency_scores.append(elem_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a5e84c-70e8-484b-aad7-2ac993b50483",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(dataset) == len(fluency_scores)\n",
    "dataset  = dataset.add_column('Fluency_scores', fluency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cbca034-9791-46ce-b70b-5bea63c0c07d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_toxic_comment</th>\n",
       "      <th>en_neutral_comment</th>\n",
       "      <th>T5_paraphrased</th>\n",
       "      <th>initial_toxicity</th>\n",
       "      <th>ideal_toxicity</th>\n",
       "      <th>resulting_toxicity</th>\n",
       "      <th>reference2masked_sim</th>\n",
       "      <th>reference2translation_sim</th>\n",
       "      <th>Fluency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he had steel balls too !</td>\n",
       "      <td>he was brave too!</td>\n",
       "      <td>He had steel balls too!</td>\n",
       "      <td>0.912212</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.917721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510213</td>\n",
       "      <td>0.900897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude should have been taken to api , he would ...</td>\n",
       "      <td>It would have been good if he went to api. He ...</td>\n",
       "      <td>The guy should have been taken to the api, he'...</td>\n",
       "      <td>0.744653</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.783338</td>\n",
       "      <td>0.912686</td>\n",
       "      <td>0.557020</td>\n",
       "      <td>0.866171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im not gonna sell the fucking picture , i just...</td>\n",
       "      <td>I'm not gonna sell the picture, i just want to...</td>\n",
       "      <td>I'm not gonna sell the picture, I just want to...</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.894954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the garbage that is being created by cnn and o...</td>\n",
       "      <td>the news that is being created by cnn and othe...</td>\n",
       "      <td>The garbage being created by CNN and other new...</td>\n",
       "      <td>0.955578</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>0.912075</td>\n",
       "      <td>0.886835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the reason they dont exist is because neither ...</td>\n",
       "      <td>The reason they don't exist is because neither...</td>\n",
       "      <td>The reason they don't exist is that neither is...</td>\n",
       "      <td>0.945480</td>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.936731</td>\n",
       "      <td>0.992926</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.654566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    en_toxic_comment  \\\n",
       "0                           he had steel balls too !   \n",
       "1  dude should have been taken to api , he would ...   \n",
       "2  im not gonna sell the fucking picture , i just...   \n",
       "3  the garbage that is being created by cnn and o...   \n",
       "4  the reason they dont exist is because neither ...   \n",
       "\n",
       "                                  en_neutral_comment  \\\n",
       "0                                  he was brave too!   \n",
       "1  It would have been good if he went to api. He ...   \n",
       "2  I'm not gonna sell the picture, i just want to...   \n",
       "3  the news that is being created by cnn and othe...   \n",
       "4  The reason they don't exist is because neither...   \n",
       "\n",
       "                                      T5_paraphrased  initial_toxicity  \\\n",
       "0                            He had steel balls too!          0.912212   \n",
       "1  The guy should have been taken to the api, he'...          0.744653   \n",
       "2  I'm not gonna sell the picture, I just want to...          0.919632   \n",
       "3  The garbage being created by CNN and other new...          0.955578   \n",
       "4  The reason they don't exist is that neither is...          0.945480   \n",
       "\n",
       "   ideal_toxicity  resulting_toxicity  reference2masked_sim  \\\n",
       "0        0.005482            0.917721              1.000000   \n",
       "1        0.006850            0.783338              0.912686   \n",
       "2        0.005215            0.005073              0.887211   \n",
       "3        0.014164            0.964304              0.804467   \n",
       "4        0.108274            0.936731              0.992926   \n",
       "\n",
       "   reference2translation_sim  Fluency_scores  \n",
       "0                   0.510213        0.900897  \n",
       "1                   0.557020        0.866171  \n",
       "2                   0.887211        0.894954  \n",
       "3                   0.912075        0.886835  \n",
       "4                   0.895799        0.654566  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataset_results = dataset.to_pandas()\n",
    "pandas_dataset_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b57d0d98-7a83-49c5-ac28-de4fda16f504",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_dataset_results.to_csv('T5_paraphrased_resV2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "commit-generation",
   "language": "python",
   "name": "commit-generation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
