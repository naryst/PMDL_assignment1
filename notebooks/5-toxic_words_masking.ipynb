{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60febde-6254-4813-a754-488518c94c7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f005305-d428-4357-9b17-9fa82de69d80",
   "metadata": {},
   "source": [
    "### Model and eval data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a7edfe-2335-4205-8b5e-76f64203b11f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# tokenizer and model weights for calculating toxisity score of the text\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\n",
    "    \"SkolkovoInstitute/roberta_toxicity_classifier\"\n",
    ")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"SkolkovoInstitute/roberta_toxicity_classifier\", device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224cc453-6ab2-4026-8e52-2c5cbb5548b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_toxisity_score(model_output):\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    scores = sigmoid(model_output.squeeze()).detach().numpy()\n",
    "    result = {\"neutral\": scores[0], \"toxic\": scores[1]}\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_classification(\n",
    "    text, classification_tokenizer=tokenizer, classification_model=model\n",
    "):\n",
    "    tokenized_text = classification_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    predictions = classification_model(tokenized_text)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940d2e07-38e5-449b-af27-730fec43bc5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"s-nlp/paradetox\"\n",
    "dataset = datasets.load_dataset(dataset_path)[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ee943-ffe2-4882-a0a1-856607e95042",
   "metadata": {},
   "source": [
    "### Generation of the masked texts for the eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1bb5a4-49a9-4000-bc0d-008d151065f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resulting_texts = []\n",
    "for sample in tqdm(dataset[\"en_toxic_comment\"]):\n",
    "    sample = sample.split(\" \")\n",
    "    for i, word in enumerate(sample):\n",
    "        output = get_classification(word, tokenizer, model)\n",
    "        result = get_toxisity_score(output)\n",
    "        toxicity_prob = result[\"toxic\"]\n",
    "        to_delete = np.random.rand() <= toxicity_prob\n",
    "        if to_delete:\n",
    "            sample[i] = \"***\"\n",
    "    resulting_texts.append(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a67e1e-fb87-4fea-891d-c3520509067e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paradetox_results = np.array(resulting_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f9ace1-fafc-4757-bb3e-225578546c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paradetox_results) == len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afce772-4c1b-4351-a838-85746346d504",
   "metadata": {},
   "source": [
    "### Evaluation of the generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b846d41c-6cfd-4468-ad1d-f1112701c270",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "simmilarity_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "cosine_simmilarity = nn.CosineSimilarity(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a536feae-a443-4060-b686-3f5163874e86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sim(text1, text2):\n",
    "    embeddings = simmilarity_model.encode([text1, text2], convert_to_tensor=True)\n",
    "    return cosine_simmilarity(embeddings[0], embeddings[1]).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f27bfdc-893b-47b7-ab48-422372da66a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"masked_result\", paradetox_results)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0605a-c969-4f52-b263-8337448a7f0f",
   "metadata": {},
   "source": [
    "### Count toxicity of predictions and references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7d82bb-b9c4-4427-8fd8-df4d83ae1dd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa64778216f4545ad1a13dcce8b672c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_toxicity_val = []\n",
    "detoxified_toxicity_val = []\n",
    "masked_toxicity_val = []\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    toxic_comments_batch, detoxified_comments_batch, masked_comments_batch = (\n",
    "        batch[\"en_toxic_comment\"],\n",
    "        batch[\"en_neutral_comment\"],\n",
    "        batch[\"masked_result\"],\n",
    "    )\n",
    "    t = tokenizer(toxic_comments_batch, return_tensors='pt', padding='max_length', truncation=True)\n",
    "    res = model(**t)\n",
    "    for elem in res.logits:\n",
    "        init_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n",
    "\n",
    "    t = tokenizer(detoxified_comments_batch, return_tensors='pt', padding='max_length', truncation=True)\n",
    "    res = model(**t)\n",
    "    for elem in res.logits:\n",
    "        detoxified_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n",
    "\n",
    "    t = tokenizer(masked_comments_batch, return_tensors='pt', padding='max_length', truncation=True)\n",
    "    res = model(**t)\n",
    "    for elem in res.logits:\n",
    "        masked_toxicity_val.append(get_toxisity_score(elem)['toxic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a736f87c-3a7b-4667-a2b1-943a17b3d638",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('initial_toxicity', init_toxicity_val)\n",
    "dataset = dataset.add_column('ideal_toxicity', detoxified_toxicity_val)\n",
    "dataset = dataset.add_column('resulting_toxicity', masked_toxicity_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de843777-3368-41a3-89ce-475fdd80aa95",
   "metadata": {},
   "source": [
    "### Count simmilarity of the references and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b55d7105-a356-4c81-ae86-00b78dab8f08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7ab4d6fddc46dfa2d238b26099ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference2masked_sim = []\n",
    "reference2translation_sim = []\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    toxic = example['en_toxic_comment']\n",
    "    nontoxic = example['en_neutral_comment']\n",
    "    masked = example['masked_result']\n",
    "    reference2masked_sim.append(get_sim(toxic, masked))\n",
    "    reference2translation_sim.append(get_sim(toxic, nontoxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69d8c650-8a6c-4c8f-b7e1-262e8f4280ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('reference2masked_sim', reference2masked_sim)\n",
    "dataset = dataset.add_column('reference2translation_sim', reference2translation_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307dd70-90a1-4182-8422-2d13b37ad821",
   "metadata": {},
   "source": [
    "## Fluency of the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94e01961-56e5-4179-b973-f4d228d99d67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fluency_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/roberta-large-cola-krishna2020\")\n",
    "fluency_model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/roberta-large-cola-krishna2020\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de62c387-8a03-4ade-829a-9079c764b374",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "616357b4-f675-48cd-993e-6133a9380582",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fluency_score(logits):\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    scores = sigmoid(logits.squeeze()).cpu().detach().numpy()\n",
    "    result = {\"Fluent\": scores[0], \"Non-Fluent\": scores[1]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb3055e6-c30b-4a8c-baaa-344e9b77391e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21f02715a1e4c89a40e98c209fbc6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fluency_scores = []\n",
    "for batch in tqdm(dataloader):\n",
    "    text = batch['masked_result']\n",
    "    tokens = fluency_tokenizer(text, return_tensors='pt', truncation=True, padding='max_length').to(device)\n",
    "    result = fluency_model(**tokens).logits\n",
    "    for elem in result:\n",
    "        elem_res = get_fluency_score(elem)['Fluent']\n",
    "        fluency_scores.append(elem_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c9547e-d9a6-4b4f-8d2e-d576bbc43b02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(dataset) == len(fluency_scores)\n",
    "dataset  = dataset.add_column('Fluency_scores', fluency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "294e148c-de4e-4bb7-bb51-0fdba880f89b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_toxic_comment</th>\n",
       "      <th>en_neutral_comment</th>\n",
       "      <th>masked_result</th>\n",
       "      <th>initial_toxicity</th>\n",
       "      <th>ideal_toxicity</th>\n",
       "      <th>resulting_toxicity</th>\n",
       "      <th>reference2masked_sim</th>\n",
       "      <th>reference2translation_sim</th>\n",
       "      <th>Fluency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he had steel balls too !</td>\n",
       "      <td>he was brave too!</td>\n",
       "      <td>he had steel balls too !</td>\n",
       "      <td>0.912212</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.912212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510213</td>\n",
       "      <td>0.880316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dude should have been taken to api , he would ...</td>\n",
       "      <td>It would have been good if he went to api. He ...</td>\n",
       "      <td>dude should have been taken to api , he would ...</td>\n",
       "      <td>0.744653</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.744653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557020</td>\n",
       "      <td>0.899550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im not gonna sell the fucking picture , i just...</td>\n",
       "      <td>I'm not gonna sell the picture, i just want to...</td>\n",
       "      <td>im not gonna sell the *** picture , i just wan...</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.903694</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.867077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the garbage that is being created by cnn and o...</td>\n",
       "      <td>the news that is being created by cnn and othe...</td>\n",
       "      <td>the *** that is being created by cnn and other...</td>\n",
       "      <td>0.955578</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>0.873326</td>\n",
       "      <td>0.912075</td>\n",
       "      <td>0.751078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the reason they dont exist is because neither ...</td>\n",
       "      <td>The reason they don't exist is because neither...</td>\n",
       "      <td>the reason they dont exist is because neither ...</td>\n",
       "      <td>0.945480</td>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.765257</td>\n",
       "      <td>0.903425</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.698454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    en_toxic_comment  \\\n",
       "0                           he had steel balls too !   \n",
       "1  dude should have been taken to api , he would ...   \n",
       "2  im not gonna sell the fucking picture , i just...   \n",
       "3  the garbage that is being created by cnn and o...   \n",
       "4  the reason they dont exist is because neither ...   \n",
       "\n",
       "                                  en_neutral_comment  \\\n",
       "0                                  he was brave too!   \n",
       "1  It would have been good if he went to api. He ...   \n",
       "2  I'm not gonna sell the picture, i just want to...   \n",
       "3  the news that is being created by cnn and othe...   \n",
       "4  The reason they don't exist is because neither...   \n",
       "\n",
       "                                       masked_result  initial_toxicity  \\\n",
       "0                           he had steel balls too !          0.912212   \n",
       "1  dude should have been taken to api , he would ...          0.744653   \n",
       "2  im not gonna sell the *** picture , i just wan...          0.919632   \n",
       "3  the *** that is being created by cnn and other...          0.955578   \n",
       "4  the reason they dont exist is because neither ...          0.945480   \n",
       "\n",
       "   ideal_toxicity  resulting_toxicity  reference2masked_sim  \\\n",
       "0        0.005482            0.912212              1.000000   \n",
       "1        0.006850            0.744653              1.000000   \n",
       "2        0.005215            0.015971              0.903694   \n",
       "3        0.014164            0.063538              0.873326   \n",
       "4        0.108274            0.765257              0.903425   \n",
       "\n",
       "   reference2translation_sim  Fluency_scores  \n",
       "0                   0.510213        0.880316  \n",
       "1                   0.557020        0.899550  \n",
       "2                   0.887211        0.867077  \n",
       "3                   0.912075        0.751078  \n",
       "4                   0.895799        0.698454  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataset_results = dataset.to_pandas()\n",
    "pandas_dataset_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "commit-generation",
   "language": "python",
   "name": "commit-generation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
