{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1129e3-1aea-480a-b4e8-53a7836dc6fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959c6db0-a461-49fa-895c-400bfc4986c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_results = pd.read_csv('BART_paraphrasing_res.csv')\n",
    "t5_results = pd.read_csv('T5_paraphrased_res.csv')\n",
    "masked_results = pd.read_csv('word_masking_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d62735-d002-470f-a7bb-a21e7435ad01",
   "metadata": {},
   "source": [
    "### Count Joint metric\n",
    "it's counted as (1 - toxicity_score) * simmilarity * fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d028b19e-6170-47b2-a4a8-a5f5ee2eedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_results['J'] = (1 - bart_results['resulting_toxicity']) * bart_results['reference2masked_sim'] * bart_results['Fluency_score']\n",
    "masked_results['J'] = (1 - masked_results['resulting_toxicity']) * masked_results['reference2masked_sim'] * masked_results['Fluency_scores']\n",
    "t5_results['J'] = (1 - t5_results['resulting_toxicity']) * t5_results['reference2paraphrased_sim'] * t5_results['Fluency_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4736658-f2a1-454e-8ea0-58ab2afaf232",
   "metadata": {},
   "source": [
    "### Comparing Joint metric among 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003a9d16-4e89-4cbf-a04a-88ea0c0c8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5644548913585631, 0.41140514581595666, 0.46843638177436375)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_results['J'].mean(), masked_results['J'].mean(), t5_results['J'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd31249c-0308-4ca8-b4c6-bc5e686426bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained BART results: tox - 0.077, sim - 0.851, fluency - 0.726\n",
      "fintuned T5 results: tox - 0.280, sim - 0.830, fluency - 0.788\n",
      "Words masking results: tox - 0.244, sim - 0.874, fluency - 0.643\n"
     ]
    }
   ],
   "source": [
    "bart_tox = bart_results['resulting_toxicity'].mean()\n",
    "mask_tox = masked_results['resulting_toxicity'].mean()\n",
    "t5_tox = t5_results['resulting_toxicity'].mean()\n",
    "\n",
    "bart_sim = bart_results['reference2masked_sim'].mean()\n",
    "mask_sim = masked_results['reference2masked_sim'].mean()\n",
    "t5_sim = t5_results['reference2paraphrased_sim'].mean()\n",
    "\n",
    "bart_f = bart_results['Fluency_score'].mean()\n",
    "mask_f = masked_results['Fluency_scores'].mean()\n",
    "t5_f = t5_results['Fluency_scores'].mean()\n",
    "\n",
    "print(f\"pretrained BART results: tox - {bart_tox:.3f}, sim - {bart_sim:.3f}, fluency - {bart_f:.3f}\")\n",
    "print(f\"fintuned T5 results: tox - {t5_tox:.3f}, sim - {t5_sim:.3f}, fluency - {t5_f:.3f}\")\n",
    "print(f\"Words masking results: tox - {mask_tox:.3f}, sim - {mask_sim:.3f}, fluency - {mask_f:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dea4fc0-5094-4389-b898-ec9894ccd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys, os\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, \"w\")\n",
    "    sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "    sys.stderr = sys.__stderr__\n",
    "\n",
    "\n",
    "blockPrint()\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "enablePrint()\n",
    "print(\"Input your text you want to detoxify:\")\n",
    "text = 'fuck you'\n",
    "# blockPrint()\n",
    "\n",
    "# Fine-tuned model for text detoxification\n",
    "finetuned_model_chk = \"../models/T5_training_checkpoints/final_checkpoint/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_chk)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_chk, device_map=\"auto\")\n",
    "\n",
    "# Tokenizer and model weights for calculating toxicity score of the text\n",
    "tokenizer_toxicity_score = RobertaTokenizer.from_pretrained(\n",
    "    \"SkolkovoInstitute/roberta_toxicity_classifier\"\n",
    ")\n",
    "model_toxicity_score = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"SkolkovoInstitute/roberta_toxicity_classifier\"\n",
    ")\n",
    "\n",
    "text_tokenized = tokenizer(text, return_tensors=\"pt\")\n",
    "input = {\n",
    "    \"input_ids\": text_tokenized[\"input_ids\"],\n",
    "    \"attention_mask\": text_tokenized[\"attention_mask\"],\n",
    "}\n",
    "detoxified_text_tokenized = model.generate(**input, max_new_tokens=512, do_sample=True)\n",
    "text_detoxified = tokenizer.decode(\n",
    "    detoxified_text_tokenized[0], skip_special_tokens=True\n",
    ")\n",
    "enablePrint()\n",
    "print(text_detoxified)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
